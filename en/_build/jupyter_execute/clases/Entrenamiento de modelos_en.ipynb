{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01a906db",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Practical Exercise: Classification and Regression with Pima Indians Diabetes Dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split, GridSearchCV, cross_val_score\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Practical Exercise: Classification and Regression with Pima Indians Diabetes Dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3ff7b28",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14e76329",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load Dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = \u001b[43mpd\u001b[49m.read_csv(\u001b[33m'\u001b[39m\u001b[33mhttps://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\u001b[39m\u001b[33m'\u001b[39m, header=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m      3\u001b[39m df.columns = [\u001b[33m'\u001b[39m\u001b[33mpregnancies\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mglucose\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mblood_pressure\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mskin_thickness\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33minsulin\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbmi\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdiabetes_pedigree\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mage\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdiabetes\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(df.head())\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load Dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv', header=None)\n",
    "df.columns = ['pregnancies', 'glucose', 'blood_pressure', 'skin_thickness', 'insulin', 'bmi', 'diabetes_pedigree', 'age', 'diabetes']\n",
    "print(df.head())\n",
    "\n",
    "# Preprocessing\n",
    "X = df.drop(['diabetes', 'glucose'], axis=1)  # Features\n",
    "y_classification = df['diabetes']             # For classification\n",
    "y_regression = df['glucose']                  # For regression\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_class_train, y_class_test = train_test_split(X, y_classification, test_size=0.2, random_state=42)\n",
    "_, _, y_reg_train, y_reg_test = train_test_split(X, y_regression, test_size=0.2, random_state=42)\n",
    "\n",
    "# Classification: Random Forest + Grid Search\n",
    "param_grid = {'n_estimators': [50, 100], 'max_depth': [4, 6, 8]}\n",
    "clf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5)\n",
    "clf.fit(X_train, y_class_train)\n",
    "print(\"Best params (classification):\", clf.best_params_)\n",
    "\n",
    "# Regression: Ridge Regression\n",
    "alphas = [0.1, 1.0, 10.0]\n",
    "best_rmse = float('inf')\n",
    "for alpha in alphas:\n",
    "    reg = Ridge(alpha=alpha)\n",
    "    reg.fit(X_train, y_reg_train)\n",
    "    preds = reg.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_reg_test, preds))\n",
    "    print(f\"Alpha={alpha}, RMSE={rmse}\")\n",
    "\n",
    "# Cross-validation (impact of size)\n",
    "scores = cross_val_score(clf.best_estimator_, X, y_classification, cv=10)\n",
    "print(f\"Classification cross-val accuracy: {np.mean(scores):.2f} ± {np.std(scores):.2f}\")\n",
    "\n",
    "# Effect of small training set\n",
    "small_X = X_train.sample(frac=0.2, random_state=1)\n",
    "small_y = y_class_train.loc[small_X.index]\n",
    "clf_small = RandomForestClassifier().fit(small_X, small_y)\n",
    "print(\"Accuracy with small training set:\", accuracy_score(y_class_test, clf_small.predict(X_test)))\n",
    "\n",
    "# Evaluation\n",
    "# Classification\n",
    "y_pred_class = clf.predict(X_test)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_class_test, y_pred_class))\n",
    "print(\"Accuracy:\", accuracy_score(y_class_test, y_pred_class))\n",
    "\n",
    "# Regression\n",
    "def ridge_eval(alpha=1.0):\n",
    "    reg = Ridge(alpha=alpha)\n",
    "    reg.fit(X_train, y_reg_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "    print(\"Regression RMSE:\", np.sqrt(mean_squared_error(y_reg_test, y_pred)))\n",
    "    print(\"R² Score:\", r2_score(y_reg_test, y_pred))\n",
    "    return y_pred\n",
    "\n",
    "y_pred_reg = ridge_eval(alpha=1.0)\n",
    "\n",
    "# Regularization Plot\n",
    "rmses = []\n",
    "for alpha in alphas:\n",
    "    reg = Ridge(alpha=alpha)\n",
    "    reg.fit(X_train, y_reg_train)\n",
    "    pred = reg.predict(X_test)\n",
    "    rmses.append(np.sqrt(mean_squared_error(y_reg_test, pred)))\n",
    "\n",
    "plt.plot(alphas, rmses, marker='o')\n",
    "plt.title(\"Effect of Regularization (Ridge)\")\n",
    "plt.xlabel(\"Alpha\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.xscale('log')\n",
    "plt.show()\n",
    "\n",
    "# Feature Importance\n",
    "importances = clf.best_estimator_.feature_importances_\n",
    "sns.barplot(x=importances, y=X.columns)\n",
    "plt.title(\"Feature Importance (Random Forest)\")\n",
    "plt.show()\n",
    "\n",
    "# Residual Plot\n",
    "residuals = y_reg_test - y_pred_reg\n",
    "sns.scatterplot(x=y_pred_reg, y=residuals)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.title(\"Residual Plot (Ridge Regression)\")\n",
    "plt.xlabel(\"Predicted Glucose\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clases",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}